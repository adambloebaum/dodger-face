{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from face_encodings import Base, Face  # Import your database model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "engine = create_engine('sqlite:///face_encodings.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_rec_model = dlib.face_recognition_model_v1(r'C:\\Users\\adam.bloebaum\\.vscode\\driveline\\cv\\dlib_face_recognition_resnet_model_v1.dat')\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(r'C:\\Users\\adam.bloebaum\\.vscode\\driveline\\cv\\mmod_human_face_detector.dat')\n",
    "shape_predictor = dlib.shape_predictor(r\"C:\\Users\\adam.bloebaum\\.vscode\\driveline\\cv\\shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_known_encodings(session):\n",
    "    known_encodings = []\n",
    "    # If you have names or IDs, also load them\n",
    "    known_names = []\n",
    "    faces = session.query(Face).all()  # Modify according to your database schema\n",
    "\n",
    "    for face in faces:\n",
    "        # Load and deserialize the encoding\n",
    "        known_encodings.append(json.loads(face.encoding))\n",
    "        known_names.append(face.id)\n",
    "\n",
    "    return known_encodings, known_names\n",
    "\n",
    "known_encodings, known_names = load_known_encodings(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract every Nth frame from the video\n",
    "def extract_frames(video_path, frame_skip=50):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % frame_skip == 0:\n",
    "            frames.append(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect faces\n",
    "def detect_faces(frames, cnn_face_detector):\n",
    "    detected_faces = []\n",
    "\n",
    "    for frame in frames:\n",
    "        # convert the OpenCV BGR image to RGB\n",
    "        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = cnn_face_detector(rgb_image, 1)\n",
    "\n",
    "        for face in faces:\n",
    "            x, y, w, h = face.rect.left(), face.rect.top(), face.rect.width(), face.rect.height()\n",
    "            detected_faces.append(rgb_image[y:y+h, x:x+w])\n",
    "\n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_encodings(face):\n",
    "    # convert the OpenCV BGR image to RGB\n",
    "    rgb_image = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # initialize the Dlib face detector and shape predictor\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # detect faces\n",
    "    detected_faces = face_detector(rgb_image, 1)\n",
    "    if len(detected_faces) == 0:\n",
    "        # no faces found in the image, return None or an appropriate value\n",
    "        return None\n",
    "\n",
    "    # get the landmarks/parts for the face\n",
    "    shape = shape_predictor(rgb_image, detected_faces[0])\n",
    "\n",
    "    # align and crop the face using the landmarks\n",
    "    face_chip = dlib.get_face_chip(rgb_image, shape)\n",
    "\n",
    "    # compute the face descriptor\n",
    "    face_descriptor = face_rec_model.compute_face_descriptor(face_chip)\n",
    "\n",
    "    # convert the descriptor to a numpy array, then to a list, and serialize to JSON\n",
    "    encoding = np.array(face_descriptor).tolist()\n",
    "    return json.dumps(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_faces_in_video(video_path, known_encodings, known_names):\n",
    "    frames = extract_frames(video_path)\n",
    "    for frame in frames:\n",
    "        detected_faces = detect_faces([frame], cnn_face_detector)\n",
    "        for face in detected_faces:\n",
    "            face_encoding_json = extract_face_encodings(face)\n",
    "            if face_encoding_json is not None:\n",
    "                encoding = json.loads(face_encoding_json)\n",
    "\n",
    "                # Calculate distances to known encodings\n",
    "                distances = np.linalg.norm([encoding] - known_encodings, axis=1)\n",
    "                best_match_index = np.argmin(distances)\n",
    "\n",
    "                if distances[best_match_index] < 0.6:\n",
    "                    name = known_names[best_match_index]\n",
    "                    print(f\"Identified: {name}\")\n",
    "                else:\n",
    "                    print(\"Unknown face detected\")\n",
    "            else:\n",
    "                print(\"No face found in this frame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n",
      "No face found in this frame.\n"
     ]
    }
   ],
   "source": [
    "identify_faces_in_video(r\"C:\\Users\\adam.bloebaum\\.vscode\\driveline\\cv\\MoCap 91.0 mph Nov-02-2023.mp4\", known_encodings, known_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driveline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
